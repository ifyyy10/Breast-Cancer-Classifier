# -*- coding: utf-8 -*-
"""Breast Cancer Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zZ8cpQ-35ICe9HMc70wgiSu2a9ht1qTs

IMPORT ALL LIBRARIES AND MOUNT GOOGLE DRIVE
"""

!pip install wget

# import all libraries
import os
import wget
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import Input
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras import Model
from sklearn.utils import class_weight
import matplotlib.pyplot as plt
import ipywidgets as widgets
import numpy as np
from tensorflow.keras.models import load_model
from PIL import Image
from IPython.display import display, clear_output
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.densenet import preprocess_input



# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""LOAD DATASET"""

# Define paths
base_dir = '/content/drive/My Drive/Dataset_BUSI_with_GT'  # Update with your dataset path
unknown_folder = os.path.join(base_dir, 'unknown')

"""POPULATE UNKNOWN FOLDER WITH RANDOM IMAGES"""

## populate unknown folder with random images

# Define how many random images you want to download
num_images = 300  # Set this to the number of random images you need

# Download random images from Lorem Picsum
for i in range(num_images):
    image_url = f"https://picsum.photos/200/300?random={i}"  # 200x300 random image
    image_path = os.path.join(unknown_folder, f'random_image_{i}.jpg')
    wget.download(image_url, image_path)

print(f'{num_images} random images downloaded into the unknown folder.')

"""PRE-PROCESS DATA"""

# Define Image Dimensions
IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 32


# Create an ImageDataGenerator with a 20% validation split (define preprocessing strategy)
datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)


# Load and preprocess data

# Training generator
train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    color_mode='rgb',
    class_mode='categorical',
    subset='training'
)

# Validation generator
validation_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    color_mode='rgb',
    class_mode='categorical',
    subset='validation'
)

"""CALCULATE CLASS WEIGHT"""

# Assuming you have your class labels and their counts in the dataset
class_labels = train_generator.classes  # Get class labels from the training generator

# Calculate class weights
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(class_labels),
    y=class_labels
)

# Convert to dictionary for model training
class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}
print(class_weights_dict)

"""Build the Model Using DenseNet121"""

# Define input layer
input_tensor = Input(shape=(224, 224, 3))

# Load the base model with the input tensor
base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=input_tensor)

# Freeze the base model to prevent its weights from updating during initial training
base_model.trainable = False

# Define the custom top layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output_tensor = Dense(4, activation='softmax')(x)  # Assuming 4 classes

# Define the model
model = Model(inputs=input_tensor, outputs=output_tensor)

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""  TRAIN THE MODEL"""

# Add EarlyStopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=validation_generator,
    class_weight=class_weights_dict,  # Handle class imbalance
    callbacks=[early_stopping]
)

"""FINE TUNE THE DENSE NET"""

# Unfreeze some layers of DenseNet for fine-tuning
base_model.trainable = True

# Recompile the model with a lower learning rate
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""FINAL TRAINING OF THE MODEL WITH FINE-TUNING"""

# Continue training the model with fine-tuning
history_finetune = model.fit(
    train_generator,
    epochs=5,  # reduce epochs to avoid overfitting
    validation_data=validation_generator,
    class_weight=class_weights_dict,  # Continue handling class imbalance
    callbacks=[early_stopping]
)

"""SAVE TRAINED MODEL"""

# Save the model after training
model.save('/content/drive/My Drive/breast_cancer_classifier.h5')

"""PLOT TRAINING VS VALIDATION"""

# Plot training results
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(20)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""CHECK FOR PREDICTION STRENGTH USING CONFUSION MATRIX"""

# Step 1: Get the true labels and predicted labels

# Predict the labels for the validation dataset
y_pred = model.predict(validation_generator)

# Convert predictions from probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Get the true class labels
y_true = validation_generator.classes

# Step 2: Generate the confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)

# Step 3: Visualize the confusion matrix
labels = list(validation_generator.class_indices.keys())  # Class names (e.g., ['benign', 'malignant', 'normal', 'unknown'])

# Plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

"""CREATE GUI FOR TESTING MODEL"""

# Path to your model in Google Drive
model_path = '/content/drive/My Drive/breast_cancer_classifier.h5'

# Load the pre-trained model
model = load_model(model_path)

# Check the model summary to ensure it's loaded correctly
model.summary()

from tensorflow.keras.applications.densenet import preprocess_input
import io  # To handle the byte conversion

# Step 1: Create Widgets

# File upload widget for image upload
file_upload = widgets.FileUpload(
    accept='image/*',  # Accept images only
    multiple=False  # Single file upload
)

# Button to trigger prediction
predict_button = widgets.Button(
    description="Predict",
    button_style="success"  # Green color button
)

# Output widget to display image and prediction
output = widgets.Output()

# Label widget to show the prediction
prediction_label = widgets.Label("Prediction: ")

# Step 2: Define Prediction Function

def on_file_upload(change):
    """Handle image upload and display the image."""
    clear_output(wait=True)
    uploaded_file = list(change['new'].values())[0]
    img_data = uploaded_file['content']

    # Convert bytes to an image
    img = Image.open(io.BytesIO(img_data))

    with output:
        clear_output()
        display(img)

    return img

def make_prediction(img):
    """Predict the class of the uploaded image."""
    img = img.convert('RGB')  # Ensure the image is in RGB mode
    img = img.resize((224, 224))  # Resize image to fit the model input
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array = preprocess_input(img_array)  # Preprocess input as expected by DenseNet

    # Make prediction
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions, axis=1)[0]

    return predicted_class, predictions


def on_predict_clicked(b):
    """Handle the click event for the prediction button."""
    with output:
        clear_output()

        # Convert file content to image and display
        uploaded_file = list(file_upload.value.values())[0]
        img_data = uploaded_file['content']

        # Load image from bytes
        img = Image.open(io.BytesIO(img_data))
        display(img)

        # Make prediction
        predicted_class, predictions = make_prediction(img)

        # Display prediction result
        class_names = ['Benign', 'Malignant', 'Normal', 'Unknown']  # Modify as per your class names
        predicted_label = class_names[predicted_class]
        prediction_label.value = f"Prediction: {predicted_label} (Confidence: {predictions[0][predicted_class]*100:.2f}%)"

# Step 3: Event Handlers and GUI Display

# Attach file upload event
file_upload.observe(on_file_upload, names='value')

# Attach predict button click event
predict_button.on_click(on_predict_clicked)

# Display the widgets
display(widgets.VBox([file_upload, predict_button, output, prediction_label]))

# from sklearn.metrics import classification_report
# # Load the model for prediction
# model = load_model('/content/drive/MyDrive/breast_cancer_classifier.h5')


# # Function for prediction
# def classify_image(image_path):
#     img = Image.open(image_path).convert('RGB').resize((224, 224))
#     img_array = np.expand_dims(np.array(img) / 255.0, axis=0)
#     prediction = model.predict(img_array)
#     classes = ['benign', 'malignant', 'normal', 'unknown']
#     return classes[np.argmax(prediction)]


# # Create widgets
# file_upload = widgets.FileUpload(accept='image/*', multiple=False)
# output_label = widgets.Label(value="Upload an image for classification")
# classify_button = widgets.Button(description="Classify Image")

# # Button click event
# def on_classify_button_click(b):
#     for filename, file_info in file_upload.value.items():
#         with open(filename, 'wb') as f:
#             f.write(file_info['content'])
#         # Ensure the image is correctly processed
#         result = classify_image(filename)
#         output_label.value = f"Prediction: {result}"

# classify_button.on_click(on_classify_button_click)


# # Display widgets
# display(file_upload, classify_button, output_label)